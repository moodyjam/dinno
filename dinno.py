import os
from torch import optim, nn, utils, Tensor
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor
import lightning as L
from util import create_graph
from copy import deepcopy
import torch
from agent import Agent
import torch.nn.functional as F

# Simple network for MNIST generated by ChatGPT
class SimpleCNN(nn.Module):
    def __init__(self, num_classes=10):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 64 * 7 * 7)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# define the LightningModule
class DiNNO(L.LightningModule):
    def __init__(self, agent_config, graph_type="complete", fiedler_value=None, num_classes=10, B=2, rho=0.5, lr=1e-3):
        super().__init__()
        self.num_nodes = len(agent_config)
        self.G, self.G_connectivity = create_graph(num_nodes = self.num_nodes,
                                                   graph_type = graph_type,
                                                   target_connectivity = fiedler_value)
        
        base_model = SimpleCNN(num_classes=num_classes)
        self.agent_id_to_idx = {agent["id"]: i for i, agent in enumerate(agent_config)}

        # Initialize the networks for each agent
        self.agent_config = agent_config
        self.agents = nn.ModuleDict({agent["id"]: Agent(config=agent_config[i],
                                          model=deepcopy(base_model),
                                          idx=i,
                                          lr=lr)
                                          for i, agent in enumerate(self.agent_config)})
        
        self.automatic_optimization = False
        self.criterion = nn.CrossEntropyLoss()
        
        self.save_hyperparameters()

    def calculate_loss(self, curr_batch, theta_reg, curr_agent):
        x, y = curr_batch
        agent_idx = curr_agent.idx
        primal_loss = self.criterion(curr_agent.model(x), y)
        theta = torch.nn.utils.parameters_to_vector(curr_agent.model.parameters())
        # FIXME Add regularization term
        return primal_loss + curr_agent.dual.dot(theta) + self.hparams.rho * 1
        
    def training_step(self, batch, batch_idx):
        # training_step defines the train loop.
        # it is independent of forward
        if batch_idx % self.hparams.B == 0:
            # Reset the variable containing the neighbor parameters
            for agent_id in self.agents:
                curr_agent = self.agents[agent_id]
                curr_agent.reset_neighbor_params()

            # Communicate
            for agent_id in self.agents:
                curr_agent_idx = self.agent_id_to_idx[agent_id]
                curr_agent = self.agents[agent_id]
                curr_agent.update_flattened_params()
                for neighbor_idx in self.G.neighbors(curr_agent_idx):
                    neighbor_id = self.agent_config[neighbor_idx]["id"]
                    self.agents[neighbor_id].append_neighbor_params(curr_agent.get_flattened_params())

        # Technically this can be done in parallel
        for agent_id in self.agents:
            curr_agent = self.agents[agent_id]
            curr_agent_idx = self.agent_id_to_idx[agent_id]
            neighbor_params = torch.stack(curr_agent.get_neighbor_params())
            theta = curr_agent.get_flattened_params()
            curr_agent.dual += self.hparams.rho * (theta - neighbor_params).sum(0)
            theta_reg = (theta + neighbor_params) / 2
            curr_batch = batch[curr_agent_idx]
            opt = curr_agent.optimizer
            opt.zero_grad()
            loss = self.calculate_loss(curr_batch, theta_reg, curr_agent=curr_agent)
            self.manual_backward(loss)
            opt.step()

        self.log("train_loss", loss)
        return loss

    def configure_optimizers(self):
        optimizer = optim.Adam(self.parameters(), lr=1e-3)
        return optimizer

        
        